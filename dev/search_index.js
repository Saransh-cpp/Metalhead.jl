var documenterSearchIndex = {"docs":
[{"location":"contributing/#Contributing-to-Metalhead.jl","page":"Developer guide","title":"Contributing to Metalhead.jl","text":"","category":"section"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"We welcome contributions from anyone to Metalhead.jl! Thank you for taking the time to make our ecosystem better.","category":"page"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"You can contribute by fixing bugs, adding new models, or adding pre-trained weights. If you aren't ready to write some code, but you think you found a bug or have a feature request, please post an issue.","category":"page"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"Before continuing, make sure you read the FluxML contributing guide for general guidelines and tips.","category":"page"},{"location":"contributing/#Fixing-bugs","page":"Developer guide","title":"Fixing bugs","text":"","category":"section"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"To fix a bug in Metalhead.jl, you can open a PR. It would be helpful to file an issue first so that we can confirm the bug.","category":"page"},{"location":"contributing/#Adding-models","page":"Developer guide","title":"Adding models","text":"","category":"section"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"To add a new model architecture to Metalhead.jl, you can open a PR. Keep in mind a few guiding principles for how this package is designed:","category":"page"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"reuse layers from Flux as much as possible (e.g. use Parallel before defining a Bottleneck struct)\nadhere as closely as possible to a reference such as a published paper (i.e. the structure of your model should follow intuitively from the paper)\nuse generic functional builders (e.g. resnet is the core function that builds \"ResNet-like\" models)\nuse multiple dispatch to add convenience constructors that wrap your functional builder","category":"page"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"When in doubt, just open a PR! We are more than happy to help review your code to help it align with the rest of the library. After adding a model, you might consider adding some pre-trained weights (see below).","category":"page"},{"location":"contributing/#Adding-pre-trained-weights","page":"Developer guide","title":"Adding pre-trained weights","text":"","category":"section"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"To add pre-trained weights for an existing model or new model, you can open a PR. Below, we describe the steps you should follow to get there.","category":"page"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"All Metalhead.jl model artifacts are hosted using HuggingFace. You can find the FluxML account here. This documentation from HuggingFace will provide you with an introduction to their ModelHub. In short, the Model Hub is a collection of Git repositories, similar to Julia packages on GitHub. This means you can make a pull request to our HuggingFace repositories to upload updated weight artifacts just like you would make a PR on GitHub to upload code.","category":"page"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"Train your model or port the weights from another framework.\nSave the model using BSON.jl with BSON.@save \"modelname.bson\" model. It is important that your model is saved under the key model.\nCompress the saved model as a tarball using tar -cvzf modelname.tar.gz modelname.bson.\nObtain the SHAs (see the Pkg docs). Edit the Artifacts.toml file in the Metalhead.jl repository and add entry for your model. You can leave the URL empty for now.\nOpen a PR on Metalhead.jl. Be sure to ping a maintainer (e.g. @darsnack) to let us know that you are adding a pre-trained weight. We will create a model repository on HuggingFace if it does not already exist.\nOpen a PR to the corresponding HuggingFace repo. Do this by going to the \"Community\" tab in the HuggingFace repository. PRs and discussions are shown as the same thing in the HuggingFace web app. You can use your local Git program to make clone the repo and make PRs if you wish. Check out the guide on PRs to HuggingFace for more information.\nCopy the download URL for the model file that you added to HuggingFace. Make sure to grab the URL for a specific commit and not for the main branch.\nUpdate your Metalhead.jl PR by adding the URL to the Artifacts.toml.\nIf the tests pass for your weights, we will merge your PR! Your model should pass the acctest function in the Metalhead.jl test suite. If your model already exists in the repo, then these tests are already in place, and you can add your model configuration to the PRETRAINED_MODELS list in the runtests.jl file. Please refer to the ResNet tests as an example.","category":"page"},{"location":"contributing/","page":"Developer guide","title":"Developer guide","text":"If you want to fix existing weights, then you can follow the same set of steps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Metalhead","category":"page"},{"location":"#Metalhead","page":"Home","title":"Metalhead","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Metalhead.jl provides standard machine learning vision models for use with Flux.jl. The architectures in this package make use of pure Flux layers, and they represent the best-practices for creating modules like residual blocks, inception blocks, etc. in Flux. Metalhead also provides some building blocks for more complex models in the Layers module.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> ]add Metalhead","category":"page"},{"location":"#Available-models","page":"Home","title":"Available models","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Model Name Function Pre-trained?\nVGG VGG Y (w/o BN)\nResNet ResNet Y\nWideResNet WideResNet Y\nGoogLeNet GoogLeNet N\nInception-v3 Inceptionv3 N\nInception-v4 Inceptionv4 N\nInceptionResNet-v2 Inceptionv3 N\nSqueezeNet SqueezeNet Y\nDenseNet DenseNet N\nResNeXt ResNeXt Y\nMobileNetv1 MobileNetv1 N\nMobileNetv2 MobileNetv2 N\nMobileNetv3 MobileNetv3 N\nEfficientNet EfficientNet N\nMLPMixer MLPMixer N\nResMLP ResMLP N\ngMLP gMLP N\nViT ViT N\nConvNeXt ConvNeXt N\nConvMixer ConvMixer N","category":"page"},{"location":"","page":"Home","title":"Home","text":"To contribute new models, see our contributing docs.","category":"page"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can find the Metalhead.jl getting started guide here.","category":"page"},{"location":"tutorials/quickstart/#Quickstart","page":"Quickstart","title":"Quickstart","text":"","category":"section"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"using Flux, Metalhead","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"Using a model from Metalhead is as simple as selecting a model from the table of available models. For example, below we use the pre-trained ResNet-18 model.","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"using Flux, Metalhead\n\nmodel = ResNet(18; pretrain = true)","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"Now, we can use this model with Flux like any other model.","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"First, let's check the accuracy on a test image from ImageNet.","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"using Images\n\n# test image\nimg = Images.load(download(\"https://cdn.pixabay.com/photo/2015/05/07/11/02/guitar-756326_960_720.jpg\"));","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"We'll use the popular DataAugmentation.jl library to crop our input image, convert it to a plain array, and normalize the pixels.","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"using DataAugmentation, OneHotArrays\n\nDATA_MEAN = (0.485, 0.456, 0.406)\nDATA_STD = (0.229, 0.224, 0.225)\n\naugmentations = CenterCrop((224, 224)) |>\n                ImageToTensor() |>\n                Normalize(DATA_MEAN, DATA_STD)\ndata = apply(augmentations, Image(img)) |> itemdata\n\n# image net labels\nlabels = readlines(download(\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"))\n\nonecold(model(Flux.unsqueeze(data, 4)), labels)","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"Below, we train it on some randomly generated data.","category":"page"},{"location":"tutorials/quickstart/","page":"Quickstart","title":"Quickstart","text":"using OneHotArrays: onehotbatch\n\nbatchsize = 1\ndata = [(rand(Float32, 224, 224, 3, batchsize), onehotbatch(rand(1:1000, batchsize), 1:1000))\n        for _ in 1:3]\nopt = ADAM()\nps = Flux.params(model)\nloss(x, y, m) = Flux.Losses.logitcrossentropy(m(x), y)\nfor (i, (x, y)) in enumerate(data)\n    @info \"Starting batch $i ...\"\n    gs = gradient(() -> loss(x, y, model), ps)\n    Flux.update!(opt, ps, gs)\nend","category":"page"},{"location":"api/models/","page":"Models","title":"Models","text":"CurrentModule = Metalhead","category":"page"},{"location":"api/models/#Models","page":"Models","title":"Models","text":"","category":"section"},{"location":"api/models/","page":"Models","title":"Models","text":"The API reference for available models in Metalhead.jl.","category":"page"},{"location":"api/models/","page":"Models","title":"Models","text":"VGG\nResNet\nWideResNet\nGoogLeNet\nInception-v3\nInception-v4\nInceptionResNet-v2\nSqueezeNet\nDenseNet\nResNeXt\nMobileNetv1\nMobileNetv2\nMobileNetv3\nEfficientNet\nMLPMixer\nResMLP\ngMLP\nViT\nConvNeXt\nConvMixer","category":"page"},{"location":"api/models/#Metalhead.VGG","page":"Models","title":"Metalhead.VGG","text":"VGG(imsize::Dims{2}; config, inchannels, batchnorm = false, nclasses, fcsize, dropout_rate)\n\nConstruct a VGG model with the specified input image size. Typically, the image size is (224, 224).\n\nKeyword Arguments:\n\nconfig : VGG convolutional block configuration. It is defined as a vector of tuples (output_channels, num_convolutions) for each block\ninchannels: number of input channels\nbatchnorm: set to true to use batch normalization after each convolution\nnclasses: number of output classes\nfcsize: intermediate fully connected layer size (see Metalhead.vgg_classifier_layers)\ndropout_rate: dropout level between fully connected layers\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.ResNet","page":"Models","title":"Metalhead.ResNet","text":"ResNet(depth::Integer; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a ResNet model with the specified depth. ((reference)[https://arxiv.org/abs/1512.03385])\n\nArguments\n\ndepth: one of [18, 34, 50, 101, 152]. The depth of the ResNet model.\npretrain: set to true to load the model with pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: the number of output classes\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.WideResNet","page":"Models","title":"Metalhead.WideResNet","text":"WideResNet(depth::Integer; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a Wide ResNet model with the specified depth. The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block. The number of channels in outer 1x1 convolutions is the same. ((reference)[https://arxiv.org/abs/1605.07146])\n\nArguments\n\ndepth: one of [18, 34, 50, 101, 152]. The depth of the Wide ResNet model.\npretrain: set to true to load the model with pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: the number of output classes\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.GoogLeNet","page":"Models","title":"Metalhead.GoogLeNet","text":"GoogLeNet(; pretrain::Bool = false, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate an Inception-v1 model (commonly referred to as GoogLeNet) (reference).\n\nArguments\n\npretrain: set to true to load the model with pre-trained weights for ImageNet\nnclasses: the number of output classes\n\nwarning: Warning\nGoogLeNet does not currently support pretrained weights.\n\nSee also googlenet.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.SqueezeNet","page":"Models","title":"Metalhead.SqueezeNet","text":"SqueezeNet(; pretrain::Bool = false, inchannels::Integer = 3,\n       nclasses::Integer = 1000)\n\nCreate a SqueezeNet (reference).\n\nArguments\n\npretrain: set to true to load the pre-trained weights for ImageNet\ninchannels: number of input channels.\nnclasses: the number of output classes.\n\nSee also squeezenet.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.DenseNet","page":"Models","title":"Metalhead.DenseNet","text":"DenseNet(config::Integer; pretrain::Bool = false, nclasses::Integer = 1000)\nDenseNet(transition_configs::NTuple{N,Integer})\n\nCreate a DenseNet model with specified configuration. Currently supported values are (121, 161, 169, 201) (reference). Set pretrain = true to load the model with pre-trained weights for ImageNet.\n\nwarning: Warning\nDenseNet does not currently support pretrained weights.\n\nSee also Metalhead.densenet.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.ResNeXt","page":"Models","title":"Metalhead.ResNeXt","text":"ResNeXt(depth::Integer; pretrain::Bool = false, cardinality::Integer = 32,\n        base_width::Integer = 4, inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a ResNeXt model with the specified depth, cardinality, and base width. ((reference)[https://arxiv.org/abs/1611.05431])\n\nArguments\n\ndepth: one of [18, 34, 50, 101, 152]. The depth of the ResNet model.\npretrain: set to true to load the model with pre-trained weights for ImageNet. Supported configurations are:\ndepth 50, cardinality of 32 and base width of 4.\ndepth 101, cardinality of 32 and base width of 8.\ndepth 101, cardinality of 64 and base width of 4.\ncardinality: the number of groups to be used in the 3x3 convolution in each block.\nbase_width: the number of feature maps in each group.\ninchannels: the number of input channels.\nnclasses: the number of output classes\n\nAdvanced users who want more configuration options will be better served by using resnet.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.MobileNetv1","page":"Models","title":"Metalhead.MobileNetv1","text":"MobileNetv1(width_mult = 1; inchannels::Integer = 3, pretrain::Bool = false,\n            nclasses::Integer = 1000)\n\nCreate a MobileNetv1 model with the baseline configuration (reference). Set pretrain to true to load the pretrained weights for ImageNet.\n\nArguments\n\nwidth_mult: Controls the number of output feature maps in each block (with 1.0 being the default in the paper; this is usually a value between 0.1 and 1.4)\ninchannels: The number of input channels.\npretrain: Whether to load the pre-trained weights for ImageNet\nnclasses: The number of output classes\n\nSee also Metalhead.mobilenetv1.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.MobileNetv2","page":"Models","title":"Metalhead.MobileNetv2","text":"MobileNetv2(width_mult = 1.0; inchannels::Integer = 3, pretrain::Bool = false,\n            nclasses::Integer = 1000)\n\nCreate a MobileNetv2 model with the specified configuration. (reference). Set pretrain to true to load the pretrained weights for ImageNet.\n\nArguments\n\nwidth_mult: Controls the number of output feature maps in each block (with 1.0 being the default in the paper; this is usually a value between 0.1 and 1.4)\npretrain: Whether to load the pre-trained weights for ImageNet\ninchannels: The number of input channels.\nnclasses: The number of output classes\n\nSee also Metalhead.mobilenetv2.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.MobileNetv3","page":"Models","title":"Metalhead.MobileNetv3","text":"MobileNetv3(config::Symbol; width_mult::Real = 1, pretrain::Bool = false,\n            inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreate a MobileNetv3 model with the specified configuration. (reference). Set pretrain = true to load the model with pre-trained weights for ImageNet.\n\nArguments\n\nconfig: :small or :large for the size of the model (see paper).\nwidth_mult: Controls the number of output feature maps in each block (with 1.0 being the default in the paper; this is usually a value between 0.1 and 1.4)\npretrain: whether to load the pre-trained weights for ImageNet\ninchannels: The number of channels in the input.\nnclasses: the number of output classes\n\nSee also Metalhead.mobilenetv3.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.EfficientNet","page":"Models","title":"Metalhead.EfficientNet","text":"EfficientNet(config::Symbol; pretrain::Bool = false)\n\nCreate an EfficientNet model (reference). See also efficientnet.\n\nArguments\n\nconfig: name of default configuration (can be :b0, :b1, :b2, :b3, :b4, :b5, :b6, :b7, :b8)\npretrain: set to true to load the pre-trained weights for ImageNet\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.MLPMixer","page":"Models","title":"Metalhead.MLPMixer","text":"MLPMixer(config::Symbol; patch_size::Dims{2} = (16, 16), imsize::Dims{2} = (224, 224),\n         inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a model with the MLPMixer architecture. (reference).\n\nArguments\n\nconfig: the size of the model - one of small, base, large or huge\npatch_size: the size of the patches\nimsize: the size of the input image\ndrop_path_rate: Stochastic depth rate\ninchannels: the number of input channels\nnclasses: number of output classes\n\nSee also Metalhead.mlpmixer.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.ResMLP","page":"Models","title":"Metalhead.ResMLP","text":"ResMLP(config::Symbol; patch_size::Dims{2} = (16, 16), imsize::Dims{2} = (224, 224),\n       inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a model with the ResMLP architecture. (reference).\n\nArguments\n\nconfig: the size of the model - one of small, base, large or huge\npatch_size: the size of the patches\nimsize: the size of the input image\ninchannels: the number of input channels\nnclasses: number of output classes\n\nSee also Metalhead.mlpmixer.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.gMLP","page":"Models","title":"Metalhead.gMLP","text":"gMLP(config::Symbol; patch_size::Dims{2} = (16, 16), imsize::Dims{2} = (224, 224),\n     inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a model with the gMLP architecture. (reference).\n\nArguments\n\nconfig: the size of the model - one of small, base, large or huge\npatch_size: the size of the patches\nimsize: the size of the input image\ninchannels: the number of input channels\nnclasses: number of output classes\n\nSee also Metalhead.mlpmixer.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.ViT","page":"Models","title":"Metalhead.ViT","text":"ViT(config::Symbol = base; imsize::Dims{2} = (256, 256), inchannels::Integer = 3,\n    patch_size::Dims{2} = (16, 16), pool = :class, nclasses::Integer = 1000)\n\nCreates a Vision Transformer (ViT) model. (reference).\n\nArguments\n\nconfig: the model configuration, one of [:tiny, :small, :base, :large, :huge, :giant, :gigantic]\nimsize: image size\ninchannels: number of input channels\npatch_size: size of the patches\npool: pooling type, either :class or :mean\nnclasses: number of classes in the output\n\nSee also Metalhead.vit.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.ConvNeXt","page":"Models","title":"Metalhead.ConvNeXt","text":"ConvNeXt(config::Symbol; inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a ConvNeXt model. (reference)\n\nArguments\n\nconfig: The size of the model, one of tiny, small, base, large or xlarge.\ninchannels: The number of channels in the input.\nnclasses: number of output classes\n\nSee also Metalhead.convnext.\n\n\n\n\n\n","category":"type"},{"location":"api/models/#Metalhead.ConvMixer","page":"Models","title":"Metalhead.ConvMixer","text":"ConvMixer(config::Symbol; inchannels::Integer = 3, nclasses::Integer = 1000)\n\nCreates a ConvMixer model. (reference)\n\nArguments\n\nconfig: the size of the model, either :base, :small or :large\ninchannels: The number of channels in the input.\nnclasses: number of classes in the output\n\n\n\n\n\n","category":"type"}]
}
